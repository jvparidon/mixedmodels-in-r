---
title: "Using Julia's MixedModels.jl in R"
author: "JP van Paridon"
date: "2022-12-02"
output: rmarkdown::github_document
---

```{r setup}

library(JuliaCall)
library(Matrix)
library(lme4)
library(tictoc)

```

## Why fit mixed-effects models with `MixedModels.jl` instead of `lme4`?

`lme4` has lots of great qualities: It's free and easy to install, it's fairly straightforward to use if you know R, and its syntax and functionality is stable (i.e. it's no longer undergoing any major changes). That last quality has downsides, too: Because `lme4` is no longer being actively developed, any new work done on it consists of bug fixes rather than major improvements. When all you want to do is fit a reasonably _small, simple_ linear or generalized linear mixed-effects model, that lack of new development is a net positive. However, when you're trying to fit a harder model (e.g. using a very large dataset or maximal model with many parameters) or the same model many times (e.g. when doing some kind of bootstrapping) `lme4` can start to feel very limited. Models may take very long to fit, or you may encounter convergence issues.

`MixedModels.jl` solves a number of issues with `lme4`. Most of these are not material to psychologists, but one that _does_ matter is that `MixedModels.jl` can fit models much faster than `lme4` because it is written in `Julia`.[^1] This potential for speedup is the reason that some of `lme4`'s contributors switched to working on `MixedModels.jl`, despite `Julia` having a much smaller user-base than `R`.

[^1]: The main reason that a `Julia` package can be much faster than an `R` package is that `R` is _interpreted_ whereas `Julia` is _compiled_. Broadly speaking, an interpreted language takes the code you write and does a fast but suboptimal translation to low-level machine instructions every time you run the code, while a compiled language takes a block of code and carefully optimizes it to very fast machine code. This optimization takes some time, which means that running code just once is often slower in a compiled language. The optimized code is stored however, so that when you run a block of code multiple times the speedup can be significant. Since fitting a mixed-effects model generally involves running a block of model fitting code hundreds or thousands of times, switching to a compiled language like `Julia` comes with a big speed advantage.

Because `MixedModels.jl` is still undergoing active development, you can expect new features to be added over time. Actively developed projects sometimes break backward compatibility by e.g. removing features, but `MixedModels.jl` uses semantic versioning, meaning that if large, breaking changes are introduced, the developers will change the major version number (e.g. if they are currently at v1.4.2, a breaking change means they will go to v2.0.0) making it easy to see these changes coming and revert to a compatible version, if necessary.

That said, `MixedModels.jl` is not an experimental package; several companies use it commercially, so reliability is important and the developers are thoughtful about making changes.


## Why you don't need to switch from `R` to `Julia` to use `MixedModels.jl`

Despite the advantages that `Julia` offers, most psychologists are probably not moving away from `R` anytime soon. There are simply too many advantages to using `R`: Many people can read and write it, it has a great package ecosystem for data cleaning, analysis, and visualization and many people are familiar with these packages, and as a result many existing data cleaning and modeling workflows are implemented in `R`. On top of all that, learning a new language is a major time investment that many people find hard to justify.

Luckily, there is no need to fully switch to `Julia` (or even learn much `Julia` syntax) just to take advantage of `MixedModels.jl` model fitting functionality. `R` has a package called `JuliaCall` that lets you run `Julia` commands from the `R` command line, from RMarkdown documents, and from inside RStudio. You can use `JuliaCall` to move data back and forth between `Julia` and your `R` session, fit models using `MixedModels.jl`, and do whatever else you may want to do in `Julia` rather than `R`.

All that's required to use `JuliaCall` is an existing `Julia` install on your system, and a little bit of knowledge of whatever `Julia` command you want to run.


## Installing Julia

Installing `Julia` is pretty easy. The package management system is less error-prone than the `R` or `Python` system and you won't really have to think about it much while using `JuliaCall`.

To install `Julia` go to [julialang.org/downloads](https://julialang.org/downloads/) and download the **current stable release** for your system. If you have a MacBook make sure to download the correct version for your processor architecture (M1/M2 or Intel).

After installing, go to [julialang.org/downloads/platform](https://julialang.org/downloads/platform/) for some platform-specific instructions like how to add the `Julia` binaries to your `PATH` variable. (This is important for using `JuliaCall` later!)


## Setting up Julia environment

Now that you have `Julia` installed, all you need to do is install the `JuliaCall` `R` package (e.g. through the RStudio interface) and then we can set up the `Julia` environment.

```{r julia_setup}

# set up and start the Julia instance
julia_setup()

```

If you do not see similar output when you call `julia_setup()`, something might be wrong with your `Julia` install or the binaries may not be on your `PATH` variable. If you encounter any problems, please refer back to the installation instructions.

```{r julia_packages}

# install MixedModels.jl and JelyMe4.jl if necessary
julia_install_package_if_needed("MixedModels")
julia_install_package_if_needed("JellyMe4")
julia_install_package_if_needed("DataFrames")

# load Julia packages
julia_library("RCall")
julia_library("MixedModels")
julia_library("JellyMe4")
julia_library("DataFrames")

# load an example dataset from MixedModels.jl into R
julia_command("kb07 = DataFrame(MixedModels.dataset(:kb07));")
kb07 <- julia_eval("kb07")

```

## Fitting a big model in `R`

To set a baseline for the time cost of fitting a complex mixed-effects model in `lme4`, we're going to follow [an example from Doug Bates](https://rpubs.com/dmbates/377897)[^2], one of the lead developers behind both `lme4` and `MixedModels.jl`, and use the `kb07` dataset that is included with `MixedModels.jl` for use in tutorials such as this one. To get a nice, complex model for my demonstration, we'll specify the maximal model that's licensed by the data generating process: All main effects, all possible interactions between these main effects, and random effects by both item and subject (including random intercepts and random slopes for all main effect and interactions between main effects).[^3] This model will be singular, but that's not something we need to worry about in this demonstration.

[^2]: Sadly Doug's original vignette is based on older versions of `Julia`, `R`, and their respective packages, and seems to no longer work with more recent versions.

[^3]: To quote Doug: "Let me be clear that I do not advocate fitting such models", fitting maximal models by default is a somewhat controversial topic; we're just fitting the maximal model here as a stand-in for any other complex models that you may want to fit, not because it's necessarily the most appropriate model for the data.

We've already loaded the data from the `Julia` session into the `R` session in the block of code above so that we can focus on model fitting in the code below, but if you're working in `R` and offloading model fitting to `Julia`, you'll generally want to work in the opposite direction and load your data from the `R` session into the `JuliaCall` session. How to do this will be demonstrated later in this vignette.

```{r lme4_model}

tic("lme4 model")
m <- lmer(rt_trunc ~ 1 + spkr * prec * load +
            (1 + spkr * prec * load | subj) +
            (1 + spkr * prec * load | item),
          kb07, REML = FALSE)
toc()

summary(m)

```

This model takes a bit of time to fit in `R`, around two minutes on my MacBook. Two minutes is generally not prohibitive when fitting a single model, but imagine a model with more parameters still, or fitting a model to a much larger dataset. Even worse, imagine you wanted to use bootstrapping to get confidence intervals for your parameter estimates and wanted to refit this model 1000 times. Instead of two minutes, you would be looking at closer to 2000 minutes of model fitting, more than 30 hours to get CIs for a single model![^4]

[^4]: Obviously the scenario presented here may not apply to you. You may only fit very minimal models, in which case `lme4` probably works just fine for you. Alternatively, 30 hours may not sound like a very long time to you, because you regularly fit much more complicated models and do a lot of bootstrap resampling! In that case, `MixedModels.jl` most definitely _is_ for you. Always make a case-by-case evaluation when deciding which modeling tools to use. Is the additional hassle worth it for the speed advantage, yes or no?

## Fitting the model in Julia

Fitting the same model in `MixedModels.jl` is not overly complicated. `Julia` and `MixedModels.jl` syntax differs a bit from `R` and `lme4`, but luckily the actual model formula works pretty much exactly the same.

First, we pass the dataset from `R` to the `JuliaCall` session using `julia_assign("Julia_variable_name", R_variable_name)`. Then, we construct the `MixedModels.jl` model fitting call using `julia_command()`. The call is passed as a string, and inside that string is built up as follows:

1. A variable assignment so that we can retrieve the fitted model from the `JuliaCall` session later
2. A `fit!()` call that tells `Julia` to fit the specified model
3. A `LinearMixedModel()` call, equivalent to `lmer()`
4. An `@formula()` call, to specify the model formula using the familiar syntax
5. The formula, dataset, and additional but straightforward parameters such as `REML` and `progress` (note that unlike in `R`, boolean values in `Julia` are lowercase: `true` and `false`!)

```{r julia_model}

# the dataframe is already present in the Julia instance
# because that's where we retrieved it from
# but in case you want to use data from an R dataframe, this is how to get it
julia_assign("kb07", kb07)

# specify and fit the model in Julia using MixedModels.jl
tic("MixedModels.jl model")
julia_command("jm = fit!(LinearMixedModel(@formula(
  rt_trunc ~ 1 + spkr * prec * load +
    (1 + spkr * prec * load | subj) +
    (1 + spkr * prec * load | item)), kb07), REML=false, progress=false);")
toc()

# retrieve the model from Julia
jm <- julia_eval("robject(:lmerMod, Tuple([jm, kb07]));", need_return = "R")
summary(jm)

```

The fitted model is retrieved from the `JuliaCall` session using `julia_eval()`, and thanks to some magic from the `JellyMe4.jl` package, it is stored in `R` as an `lme4`-style model object. We can then simply summarize it using `summary()`. As you can see, the model yields numerically similar results to the one we fitted in `R`, but it took only about 15 seconds to fit, a significant speedup!

## Wrap it in a function

To make calling `MixedModels.jl` from `R` more convenient (and not have to remember a lot of `Julia` syntax!) we can wrap this process in a function call. (I'm borrowing this idea and most of the following code from [Phillip Alday](https://github.com/palday), one of the `MixedModels.jl` developers)

```{r jmer_function}

jmer <- function(formula, data, REML = TRUE, progress = TRUE) {
    jf <- deparse1(formula)
    jreml = ifelse(REML, "true", "false")
    jprog = ifelse(progress, "true", "false")
    julia_assign("jmerdat", data)
    julia_command(sprintf(
      "jmermod = fit!(LinearMixedModel(@formula(%s), jmerdat), REML=%s, progress=%s);",
      jf, jreml, jprog
    ))
    julia_eval("robject(:lmerMod, Tuple([jmermod, jmerdat]));", need_return = "R")
}

tic("jmer model")
jm <- jmer(rt_trunc ~ 1 + spkr * prec * load +
             (1 + spkr * prec * load | subj) +
             (1 + spkr * prec * load | item),
            kb07, REML = FALSE, progress = FALSE)
toc()

summary(jm)

```

This model fit took even less time than the previous `MixedModels.jl` call, because the `Julia` JIT compiler had already compiled this model during this session and is smart enough to not recompile it when we call it again. The time consumed here is therefore almost purely model fitting time, and that turns out to be just ~7 seconds in `MixedModels.jl`. That reduces the time cost of 1000 refits for bootstrapping to 7000 seconds, or just 2 hours, rather than 30 hours when using `lme4`.

If you want to fit your own models in `MixedModels.jl` using `JuliaCall`, you can simply:

1. Copy the block of `JuliaCall` setup code and the `jmer()` function definition
2. Assign your dataset from your `R` session to your `JuliaCall` session using `julia_assign()`
3. Specify and fit the model using `jmer()` instead of `lmer()`
4. Store the returned results in an `R` variable so you can e.g. call `summary()` on it

If you run into any issues, just shoot me an email at [vanparidon@wisc.edu](mailto:vanparidon@wisc.edu)!
